{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"10Uncertainty.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"M2POz32KyolU"},"source":["# UNCERTAINTY"]},{"cell_type":"markdown","metadata":{"id":"hqQJXDSSE29t"},"source":["> by Dr Juan H Klopper\n","\n","- Research Fellow\n","- School for Data Science and Computational Thinking\n","- Stellenbosch University"]},{"cell_type":"markdown","metadata":{"id":"gC8s3STptHqI"},"source":["## INTRODUCTION"]},{"cell_type":"markdown","metadata":{"id":"qFn3CTp8tJp3"},"source":["One the most important aspects of Data Science is the ability to express uncertainty in our data and in our results."]},{"cell_type":"markdown","metadata":{"id":"IBGhg7T2tSk2"},"source":["The genration of random variables is not precise. Take a simple example such as height measurement. We only measure up to a set precision. If the measurement is done by hand, we cannot guarantee accuracy."]},{"cell_type":"markdown","metadata":{"id":"0zkb76gHtr-E"},"source":["We also only work with sample of a population. Most often, there is a large difference in the population size and the sample size. We therefor don't approach the population parameters with our test statisics. There is uncertainty in our results."]},{"cell_type":"markdown","metadata":{"id":"mdi7VKg_t8VN"},"source":["In this notebook we learning to understand uncertainty and how to calculate and express the uncertainty in our results. This will be done by investigating the method of __bootstrapping__. Later we will learn how to calculate __confidence intervals__."]},{"cell_type":"markdown","metadata":{"id":"yMKtZ_DsyySe"},"source":["## PACKAGES USED IN THIS NOTEBOOK"]},{"cell_type":"markdown","metadata":{"id":"H3uu_RleuPal"},"source":["We see all the familiar, industry standard package imported below."]},{"cell_type":"code","metadata":{"id":"DtzY81Hy21l1"},"source":["import numpy as np # Numerical analysis\n","from scipy import stats # Statistical module\n","from pandas import DataFrame # Importing only the DataFrame function from pandas"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Te9yc3Ho4a3u"},"source":["# Data visualisation\n","import plotly.express as px\n","import plotly.graph_objects as go\n","import plotly.figure_factory as ff\n","import plotly.io as pio"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vAOY696OcM_i"},"source":["# Setting a different plotting theme\n","pio.templates.default = 'ggplot2'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TAs0UMF-0QxA"},"source":["## BOOTSTRAPPING"]},{"cell_type":"markdown","metadata":{"id":"lAwcxct20SmW"},"source":["__Bootstrapping__ is the technique of multiple resampling for our given sample. _New_ samples are generated by drawning, at random, from the original sample set, with replacement."]},{"cell_type":"markdown","metadata":{"id":"znpia8D20oE0"},"source":["In the code below, we generate random values for a variable in a population and then take a random sample from the population. Since we designed the population, we know the parameters of the variable. The variable is named `population` and the values are taken from a normal distribution with a mean of $100$ and a standard deviation of $10$."]},{"cell_type":"code","metadata":{"id":"3aSIpLzf0-G0"},"source":["np.random.seed(10)\n","population = stats.norm.rvs(\n","    loc=100, # Mean 100\n","    scale = 10, # Standard deviation 10\n","    size=20000 # Population size\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TOOevoSi17ou"},"source":["We can calculate the exact mean and standard deviation of the variable in the population (both are parameters)."]},{"cell_type":"code","metadata":{"id":"nGhQDMP62BnO"},"source":["np.mean(population) # Mean parameter"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cne1q2e22EM3"},"source":["np.std(population) # Standard deviation parameter"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zo1oSiBZ1WSH"},"source":["For our study, we randomly select $50$ individuals from the population. Note the use of the `replace` argument and its value `False`. We do not want to select the same subject twice."]},{"cell_type":"code","metadata":{"id":"niYH2OTv1uPj"},"source":["np.random.seed(1) # Reproducible results\n","sample = np.random.choice(\n","    population,\n","    size=50,\n","    replace=False # Fifty seperate individuals\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WiinGeJY2NND"},"source":[" We calculate the mean and standard deviation of the sample (two statistics)."]},{"cell_type":"code","metadata":{"id":"YyB7X1nL2Pxz"},"source":["np.mean(sample) # Mean statistic"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0kv1jY5E2hSE"},"source":["np.std(sample) # Standard deviation parameter"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eul52tcv2l0A"},"source":["The statistics are not the same as the parameters."]},{"cell_type":"markdown","metadata":{"id":"B_9xZI-M2H1u"},"source":["The process of boostrapping resamples multiple times from the sample and records the statistic each time. This gives us a distribution of the statistic. Each resample must have the same sample size as the original sample. This is done with replacement, else we would simply return the same sample each time. __Replacement__ then simply refers to the fact that we return a subject for possible reselection every time. Since we want the same sample size in each new bootstrapped sample, we will have some subjects occur more than once in each new sample."]},{"cell_type":"markdown","metadata":{"id":"edDFBzAv3kjl"},"source":["We use list comprehesnion below to build a list of $1000$ resampled means. Note below that we set the `replace` argument to `True` and the sample size in the `choice` function is the same as the original sample."]},{"cell_type":"code","metadata":{"id":"q_Q41G1d3WDf"},"source":["means = [np.mean(np.random.choice(sample, 50, replace=True)) for i in range(1000)]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0IXyXV774JSr"},"source":["The `create_displot` function from the figure_factory module of the plotly package provides us with a histogram and a _normal_ curve based on the data. We note that the plot includes the population mean."]},{"cell_type":"code","metadata":{"id":"4kk2DQsO30tN"},"source":["ff.create_distplot(\n","    [means],\n","    ['Resampled means'],\n","    curve_type='normal'\n",").update_layout(\n","    title='Sampling distribution of means',\n","    xaxis=dict(title='Bootstrapped means'),\n","    yaxis=dict({'title':'Density'})\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"af2r3bbI4dvx"},"source":["Now we can use percentiles to consider the middle $95$% of values. We ask what value would represent a percentile of $2.5$% and what value would represent a percentile of $97.5$%. We have to be careful when working with percentiles, though. We have an infinite number of percentile values (if we use decimal values as we do here). We do not have an inifinite number of means. There can also be ties (means with the same value). For this reason, we view the percentiles as the following steps. As as example, we use a percentile of $2.5$% and a sample size of $n$.\n","\n","1. Sort the collection in ascending order\n","2. Calculate $k$, which is $2.5$% of $n$ (shown in (1) below)\n","3. If $k$ is a whole number then the $k$-th value in the ordered collection represents the $2.5$% percentile.\n","4. Else, round $k$ up to the nearest whole number and select that value from the ordered collection."]},{"cell_type":"markdown","metadata":{"id":"YNhYQ1WD6LD7"},"source":["$$k = \\frac{2.5}{100} n \\tag{1}$$"]},{"cell_type":"markdown","metadata":{"id":"2SS0y7BR8pAR"},"source":["We are interested in the values representing the $2.5$% and the $97.5$% percentiles. These are calculated below and assigned to appropriately named computer variables."]},{"cell_type":"code","metadata":{"id":"oi4xDRRg6kun"},"source":["k_2_5 = 2.5 / 100 * 1000\n","k_2_5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j_UuiOox7PdI"},"source":["k_97_5 = 97.5 / 100 * 1000\n","k_97_5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L-F8dlD684mJ"},"source":["Since Python is $0$-indexed, we want the $24$-th and $974$-th values in the ordered array of resampled means."]},{"cell_type":"code","metadata":{"id":"9lJkw7Qa6uTX"},"source":["sorted_means = np.sort(means)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8S73xfgv6-W-"},"source":["sorted_means[24]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uKu__ezh7ZWC"},"source":["sorted_means[974]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SaIy19gM9EYd"},"source":["Below, we create another distribution plot. It indicates the percentile values and the population mean."]},{"cell_type":"code","metadata":{"id":"Fbcu6l4a7qFE"},"source":["ff.create_distplot(\n","    [means],\n","    ['Resampled means'],\n","    curve_type='normal'\n",").add_trace(\n","    go.Scatter(\n","        x=[sorted_means[24], sorted_means[24]],\n","        y=[0, 0.2],\n","        name='2.5%',\n","        mode='lines',\n","        marker=dict({'color':'orange'})\n","    )\n",").add_trace(\n","    go.Scatter(\n","        x=[sorted_means[974], sorted_means[974]],\n","        y=[0, 0.2],\n","        name='97.5%',\n","        mode='lines',\n","        marker=dict({'color':'orange'})\n","    )\n",").add_trace(\n","    go.Scatter(\n","        x=[np.mean(population), np.mean(population)],\n","        y=[0, 0.2],\n","        name='Population mean',\n","        mode='lines',\n","        marker=dict({'color':'green'})\n","    )\n",").update_layout(\n","    title='Sampling distribution of means',\n","    xaxis=dict(title='Bootstrapped means'),\n","    yaxis=dict({'title':'Density'})\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g4oOv-Rz9MLT"},"source":["We note that the area between the orange lines represent $95$% of the area under the curve. We also note that the population parameters falls within these bounds. We could have chosen a different area under the curve. At $80$%, the population mean would be outside of the bounds. For $80$% we have $10$% on either side."]},{"cell_type":"code","metadata":{"id":"fIxiqTFr-CF2"},"source":["ff.create_distplot(\n","    [means],\n","    ['Resampled means'],\n","    curve_type='normal'\n",").add_trace(\n","    go.Scatter(\n","        x=[sorted_means[99], sorted_means[99]],\n","        y=[0, 0.2],\n","        name='10%',\n","        mode='lines',\n","        marker=dict({'color':'orange'})\n","    )\n",").add_trace(\n","    go.Scatter(\n","        x=[sorted_means[899], sorted_means[899]],\n","        y=[0, 0.2],\n","        name='90%',\n","        mode='lines',\n","        marker=dict({'color':'orange'})\n","    )\n",").add_trace(\n","    go.Scatter(\n","        x=[np.mean(population), np.mean(population)],\n","        y=[0, 0.2],\n","        name='Population mean',\n","        mode='lines',\n","        marker=dict({'color':'red'})\n","    )\n",").update_layout(\n","    title='Sampling distribution of means',\n","    xaxis=dict(title='Bootstrapped means'),\n","    yaxis=dict({'title':'Density'})\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aPyZK8TR-oBU"},"source":["The (percentage) bounds are termed __confidence levels__ and the actual values at those bounds are the __confidence intervals__. At first then, we calculated for a $95$% confidence level and returned the $95$% confidence interval values."]},{"cell_type":"markdown","metadata":{"id":"CExlm9rs_A6S"},"source":["Below, we revisit our sample static and $95$% confidence intervals."]},{"cell_type":"code","metadata":{"id":"r23c_tlI_I8V"},"source":["np.mean(sample) # Sample mean"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eaYCabeQ_Lr1"},"source":["sorted_means[24] # Lower bound"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nH3g2_IF_U6n"},"source":["sorted_means[974] # Upper bound"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UC_JPisX_aCU"},"source":["When expressing the uncertainty in our sample statistic we would then state: _The variable mean in the sample was $97.8$  ($95$% confidence interval $94.4$ - $100.9$)._"]},{"cell_type":"markdown","metadata":{"id":"V6OCEHO-_zzL"},"source":["Does this mean that we are $95$% confident that the population parameter is within the confidence interval? NO. The confidence intervals state that if we were to repeat the experiment $100$ times, we would find the population parameter in $95$ of the repeat experiments."]},{"cell_type":"markdown","metadata":{"id":"Mcj3TIoCCMzR"},"source":["## CONFIDENCE INTERVALS USING SCIPY"]},{"cell_type":"markdown","metadata":{"id":"-QPnEtTyCSNc"},"source":["We have seen the use of the _t_ distribution. It is commonly used in statistical test, especially when we do not know the population parameters. The `interval` function in the stats module of the scipy package can be used to calculate the confidence intervals given a confidence level."]},{"cell_type":"markdown","metadata":{"id":"5bC2R7RGCuwK"},"source":["We use the `t.interval` function below for the _t_ distribution. The `alpha` argument is the confidence level (in percentage). The `df` argument is the degrees of freedom, which is the sample size minus the number of groups (we only had a single sample group). We also need the mean (`loc` argument) and the standard error of the sample (`scale` argument with the value calculated by the `sem` function). The latter is the standard deviation divided by the square root of the sample size."]},{"cell_type":"code","metadata":{"id":"PKfG7fTO9X0N"},"source":["stats.t.interval(\n","    alpha=0.95,\n","    df=len(sample)-1,\n","    loc=np.mean(sample),\n","    scale=stats.sem(sample)\n",") "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E510Iga5Dl--"},"source":["These values are very near our bootstrapped values. As the sample size increases and the number of repeated sampling increases, the confidence intervals will be closer to these values."]},{"cell_type":"markdown","metadata":{"id":"iwvBwGWeGIuX"},"source":["## EXAMPLE USING THE MEDIAN"]},{"cell_type":"markdown","metadata":{"id":"YSgfMvKuGMI-"},"source":["We are not stuck to the mean as sample statistic. In this example, we consider the confidence intervals for the median."]},{"cell_type":"markdown","metadata":{"id":"NJgEc7H0GUix"},"source":["Below, we genarate random values taken from the $\\chi^{2}$ distribution. We imagine that the array that we create is for a continuous numerical variable in a sample. There are $200$ observations in the sample."]},{"cell_type":"code","metadata":{"id":"CWwk4SfRGqo8"},"source":["np.random.seed(12)\n","var = np.random.chisquare(df=10, size=200)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-q8LnfzIJzIE"},"source":["We calculate the sample median below."]},{"cell_type":"code","metadata":{"id":"WunEUoOeIb9b"},"source":["np.median(var)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PNjomx06JGV9"},"source":["We see a median of $9.38$."]},{"cell_type":"markdown","metadata":{"id":"TQaUdNlHIhp9"},"source":["Next, we visulise the data."]},{"cell_type":"code","metadata":{"id":"xV3TfEW7ItOg"},"source":["px.box(\n","    y=var,\n","    title='Box plot of variable values',\n","    labels={'y':'Variable values'},\n","    width=600\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MuweP2ThKU9e"},"source":["Now we use bootstrap resamples to generate a distribution of medians. Here we have $10000$ bootstrapped samples"]},{"cell_type":"code","metadata":{"id":"BYFJ3wC-KkmQ"},"source":["medians = [np.median(np.random.choice(var, 200, replace=True)) for i in range(10000)]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uEvE_5cqKzBQ"},"source":["We use again to view a distribution plot of the medians. We use the `kde` (kernel density estimate) value for the `curve_type` argument, as the distribution is not normal. "]},{"cell_type":"code","metadata":{"id":"1BLzbIsrK26Y"},"source":["ff.create_distplot(\n","    [medians],\n","    ['Resampled medians'],\n","    curve_type='kde'\n",").update_layout(\n","    title='Sampling distribution of medians',\n","    xaxis=dict(title='Bootstrapped medians'),\n","    yaxis=dict({'title':'Density'})\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IDXaR5RAL-Ac"},"source":["For a $95$% confidence level, we still use equation (1)."]},{"cell_type":"code","metadata":{"id":"BaXMUepuMDd3"},"source":["k_2_5 = 2.5 / 100 * 10000\n","k_97_5 = 97.5 / 100 * 10000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HKe6IIc8Mqcv"},"source":["k_2_5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wgjNP8bcMuUQ"},"source":["k_97_5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_kmbphb7MKmk"},"source":["We need the medians sorted and to remember to use $0$ indexing."]},{"cell_type":"code","metadata":{"id":"b23keT03MY6H"},"source":["sorted_medians = np.sort(medians)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sjpikNqjN6NI"},"source":["Now we can calculate the $95$% confidence intervals."]},{"cell_type":"code","metadata":{"id":"Y5SnmpWnMkYY"},"source":["# Lower bound\n","sorted_medians[249] # The median that represents a 2.5% percentile"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cXK7eI-HM4h6"},"source":["# Upper bound\n","sorted_medians[9749] # The median that represents a 97.5% percentile"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6-WLbRY3M_wn"},"source":["We can now plot these confidience interval values and our original median."]},{"cell_type":"code","metadata":{"id":"3ntGxLX2NInR"},"source":["ff.create_distplot(\n","    [medians],\n","    ['Resampled medians'],\n","    curve_type='kde'\n",").add_trace(\n","    go.Scatter(\n","        x=[sorted_medians[249], sorted_medians[249]],\n","        y=[0, 1.5],\n","        name='2.5%',\n","        mode='lines',\n","        marker=dict({'color':'orange'})\n","    )\n",").add_trace(\n","    go.Scatter(\n","        x=[sorted_medians[9749], sorted_medians[9749]],\n","        y=[0, 1.5],\n","        name='97.5%',\n","        mode='lines',\n","        marker=dict({'color':'orange'})\n","    )\n",").add_trace(\n","    go.Scatter(\n","        x=[np.median(var), np.median(var)],\n","        y=[0, 1.5],\n","        name='Original sample median%',\n","        mode='lines',\n","        marker=dict({'color':'green'})\n","    )\n",").update_layout(\n","    title='Sampling distribution of medians',\n","    xaxis=dict(title='Bootstrapped medians'),\n","    yaxis=dict({'title':'Density'})\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9hldhrhwOPr8"},"source":["Since the distribution of medians is not normal, we will not have a symmetric difference between the bounds and the median as the plot above shows."]},{"cell_type":"markdown","metadata":{"id":"w4XVHiVTOcRr"},"source":[" Remember that we do not know the population median and therefor we do not know if our result is the $95$ out of every $100$ cases that actually captures the population median within its bounds."]},{"cell_type":"markdown","metadata":{"id":"Q5IEjCVYFwXh"},"source":["## CONCLUSION"]},{"cell_type":"markdown","metadata":{"id":"_MDn-dSPFxdh"},"source":["Expressing uncertainty in our test statistics is an important indicator of our results in Data Science."]},{"cell_type":"code","metadata":{"id":"VUHVBvxrFwxE"},"source":[""],"execution_count":null,"outputs":[]}]}