{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"05DescriptiveStatistics.ipynb","provenance":[{"file_id":"1z-1pkhzmCeMX-d6UpGN1RlqW6s_yjtMh","timestamp":1620067145313}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Df5njCnw7K9L"},"source":["# DESCRIPTIVE STATISTICS"]},{"cell_type":"markdown","metadata":{"id":"p-bCO-TE7Ogx"},"source":["> by Dr Juan H Klopper\n","\n","- Research Fellow\n","- School for Data Science and Computational Thinking\n","- Stellenbosch University"]},{"cell_type":"markdown","metadata":{"id":"JWZAUQEhbuHb"},"source":["## INTRODUCTION"]},{"cell_type":"markdown","metadata":{"id":"rXEv0mUPbxv0"},"source":["Datasets hide information.  There is a hidden story inside of data.  It is our duty to learn as much about this information as possible."]},{"cell_type":"markdown","metadata":{"id":"FhrHAUZDmMv6"},"source":["We need a strategy to extract the information in the data. Unfortunately, humans are not good at seeing this information when staring at rows and columns of random variables.  Instead, we start the journey of discovery by summarising the data.  Calculating single values that are representative of the whole.  Values that we understand and can interpret."]},{"cell_type":"markdown","metadata":{"id":"duDDsQ-umjQK"},"source":["We start the journey in this notebook, which is all about **descriptive statistics** (summary statistics), as well as __comparative descritpive statistics__."]},{"cell_type":"markdown","metadata":{"id":"qY6Djzavbya7"},"source":["## PACKAGES FOR THIS NOTEBOOK"]},{"cell_type":"markdown","metadata":{"id":"iJnW5Mg2kIC8"},"source":["Te following packages will be used in this notebook."]},{"cell_type":"code","metadata":{"id":"7GMyMAQSbEk3"},"source":["import pandas as pd # Data import and manipulation"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LiDNMRNTwiip"},"source":["from scipy import stats # A great statistical module from the scipy package"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jCrPFrFdnTCa"},"source":["from google.colab import drive # Import a file in Google Drive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z67lrpYUdcbI"},"source":["# Format tables printed to the screen (don't put this on the same line as the code)\n","%load_ext google.colab.data_table"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"srfntVDKcQa9"},"source":["## DATA IMPORT"]},{"cell_type":"markdown","metadata":{"id":"runAmOfktIjB"},"source":["### CONNECTING TO GOOGLE DRIVE AND IMPORTING DATA"]},{"cell_type":"markdown","metadata":{"id":"VxKKdKctlC5B"},"source":["We mount our Google Drive and navigate to the directory containing the data."]},{"cell_type":"code","metadata":{"id":"5gFaqyrCcGo7"},"source":["# Log on and list files in the DATA directory of your Google Drive\n","drive.mount('/gdrive')\n","%cd '/gdrive/My Drive/DATA SCIENCE/DATA'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q0CACEgQlRfK"},"source":["The `data.csv` file in the current folder is imported and assigned to the computer variable `df`."]},{"cell_type":"code","metadata":{"id":"nzpnpiildUPE"},"source":["df = pd.read_csv('client_data.csv')  # Import the csv file"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8yXnhtOOdYya"},"source":["df  # Display the dataframe to the screen"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_2TKl25Klm45"},"source":["The data contains customer information."]},{"cell_type":"markdown","metadata":{"id":"AJ5g0VEytPeT"},"source":["### EXAMINING THE DATAFRAME OBJECT"]},{"cell_type":"markdown","metadata":{"id":"zgNzoKkTnuOW"},"source":["We investigate the data by looking at the number of subjects (rows) and the number of statistical variables (columns)."]},{"cell_type":"code","metadata":{"id":"BiEZ6TT2n7E-"},"source":["df.shape  # Using the shape attribute"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ez7uPFifoS4J"},"source":["We see 1000 customers in our data set, with data collected for 11 variables."]},{"cell_type":"markdown","metadata":{"id":"zYUsi-LPoA-Z"},"source":["Let's have a look at all the statistical variables using the `columns` attribute of the dataframe object."]},{"cell_type":"code","metadata":{"id":"_MXiaVe2oEoB"},"source":["df.columns  # Name of each column"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jX1RyII3oH6B"},"source":["Finally, we can view the data types of each variable (column)."]},{"cell_type":"code","metadata":{"id":"AB1FQEiDol5h"},"source":["df.dtypes  # Pandas data type of each column"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zXJTco4lTY9V"},"source":["The `object` notation indicates a categorical data type, `bool` indicates a Boolean data type (`True` of `False`), `int64` indicates an numerical data type (64-bit integer), and `float64` is also a numerical data type (64-bit floating point value / a number with decimal places)."]},{"cell_type":"markdown","metadata":{"id":"z--RBhkQoztR"},"source":["## COUNTING"]},{"cell_type":"markdown","metadata":{"id":"j7n5uO0_sKuD"},"source":["### FREQUENCIES"]},{"cell_type":"markdown","metadata":{"id":"Jw4pFfnEpA4B"},"source":["Counting how many times a sample space element of a categorical variable occurs is a good start in data analysis.  In our dataframe object, we have an `invest` variable, indicating how likely a customer is to make an investment based on a quationnaire that they completed.  Let's first see what the sample space elements are in this variable.  The `unique` method will return an array of the unqiue elements it finds in a specified column."]},{"cell_type":"code","metadata":{"id":"j2NszAdlpKAf"},"source":["df.invest.unique()  # The .unique() method returns the sample space elements of a column (pandas series object)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WBGb-COXpZU9"},"source":["Data on the customers indicates how likely they are to make an investment on a scale from $1$ to $5$."]},{"cell_type":"markdown","metadata":{"id":"sPATSsSGpsiZ"},"source":["We can now count how many times each of these elements appear in the `invest` column, using the `value_counts` method.  This gives us the **frequency** of each element."]},{"cell_type":"code","metadata":{"id":"cEwk4zTVp4RZ"},"source":["df.invest.value_counts()  # Counting the number of times the unique values appear"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V6toqec3qCiC"},"source":["We can express the counts as a fraction, called a **relative frequency**, dividing the frequency by the total number of observations (rows with data).  This is done by setting the `normalize` argument to `True`."]},{"cell_type":"code","metadata":{"id":"TqB3E4BRrBJY"},"source":["df.invest.value_counts(normalize=True)  # Expressing the relative frequency"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VZzl62v3rLqx"},"source":["We can multiply this by 100 to get a percentage."]},{"cell_type":"code","metadata":{"id":"sbaxut6-rXPS"},"source":["df.invest.value_counts(normalize=True) * 100  # Expressing the relative frequency as a percentage"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mR4CVCdUqKMQ"},"source":["#### Exercise"]},{"cell_type":"markdown","metadata":{"id":"ki2WTaN0qL2h"},"source":["The `children` column indicates how many children a customer has.  Calculate the frequency with which each element appears."]},{"cell_type":"code","metadata":{"id":"7dfAmGlcZ4fH"},"source":["# Frequency of number of children"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EbfUpYpJqjax"},"source":["#### Solution"]},{"cell_type":"code","metadata":{"id":"eHqEnvAQqlEG"},"source":["df.children.value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NmbMStMlsToh"},"source":["### GROUPED FREQUENCIES"]},{"cell_type":"markdown","metadata":{"id":"HkDgMd3jsbbJ"},"source":["We can calculate *combined frequencies* to consider comparative descriptive statistics.  As an example, consider the `home_loan` and the `more_than_one_vehicle` variables. Both are binary categorical variables. We can create a __contingency table__ to summarize both variables."]},{"cell_type":"markdown","metadata":{"id":"oO5VbZdOstNR"},"source":["We can do this with the pandas `crosstab()` function."]},{"cell_type":"code","metadata":{"id":"yioZnTziszlK"},"source":["pd.crosstab(df.home_loan, df.more_than_one_vehicle)  # Row and column variable"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cx_ozKYDtgOS"},"source":["The left-hand side of the table contains the sample space elements of the `home_loan` variable (listed first in the `crosstab` function). For each of the two elements, we note frequencies across the `more_than_one_vehicle` variable's two sample space elements."]},{"cell_type":"markdown","metadata":{"id":"Z_nU-yw8fwqx"},"source":["## MEASURES OF CENTRAL TENDENCY (POINT ESTIMATES)"]},{"cell_type":"markdown","metadata":{"id":"tbNCmuyEtW2h"},"source":["**Measures of central tendency** or **point estimates** are single values that are representative of a list of continuous numerical values or of a categorical variable.  Here we discuss the arithmetic mean, the median, and the mode."]},{"cell_type":"markdown","metadata":{"id":"eRFQIdV3f3kQ"},"source":["### ARITHMETIC MEAN (AVERAGE)"]},{"cell_type":"markdown","metadata":{"id":"YI7xbvbAtgeQ"},"source":["The **mean** or the **average** is simply the sum of all the continuous numerical variables divided by the number of values."]},{"cell_type":"markdown","metadata":{"id":"nIuaGkiPtl6R"},"source":["Let's start learning about the information in our data by asking some questions."]},{"cell_type":"markdown","metadata":{"id":"84JxSkA8f7L5"},"source":["- What is the mean age of all the customers?"]},{"cell_type":"markdown","metadata":{"id":"1w_fl954t5XZ"},"source":["A pandas series object has many useful methods that are geared towards summary statistics.  The `.mean()` method calculates the mean."]},{"cell_type":"code","metadata":{"id":"lnW0iZSBde3N"},"source":["# Using the .mean() method\n","df.age.mean()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0dOjaj7WgKj4"},"source":["- What is the mean value of the customers' savings?"]},{"cell_type":"code","metadata":{"id":"3TJ1fhNogA56"},"source":["# Using alternative column (variable) reference\n","df['savings'].mean()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W2vbqS-Pge9H"},"source":["- What is the mean age of the customers who have a home loan (indicated as *True* in the `home_loan` column)?"]},{"cell_type":"markdown","metadata":{"id":"MF4YroUquV4a"},"source":["We looked at conditional in the previous notebook, where we selected only certain rows in a pandas series."]},{"cell_type":"code","metadata":{"id":"zMpOcQbBgaOk"},"source":["# Using a conditional on the Smoke column\n","df[df.home_loan == True]['age'].mean()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1T7Z3timg3h4"},"source":["- What about the mean age of the customers without a home loan?"]},{"cell_type":"code","metadata":{"id":"yzFrSWOXguu5"},"source":["# Using a conditional on the Smoke column\n","df[df.home_loan == False].age.mean()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vebMvujIvaBx"},"source":["We can save a lot of time and typing by calculating the age means for both home loan group, using the `groupby` method."]},{"cell_type":"markdown","metadata":{"id":"WlwifbqdvDLQ"},"source":["The `groupby` method can create groups from the unique elements in a column and then call a method on another column."]},{"cell_type":"code","metadata":{"id":"DtqvwNbehB-w"},"source":["# Use the .groupy() method\n","df.groupby('home_loan')['age'].mean()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lyxmWsjGnCP5"},"source":["The mean age for each of the sample space elements in the `home_loan` column will be calculared. Very useful."]},{"cell_type":"markdown","metadata":{"id":"kTrVr7X9wJyC"},"source":["By the way, the `mean` method has some useful arguments.  We can use `skipna=True` to skip over any missing values (this is the default behaviour of this method).  We can also use `numeric_only=True` if there are data values that were not captured as numbers."]},{"cell_type":"markdown","metadata":{"id":"JKYNO02bwQ_Z"},"source":["### GEOMETRIC MEAN"]},{"cell_type":"markdown","metadata":{"id":"byJiOpjXwS_5"},"source":["The **geometric mean** multiplies all the continous numerical variables and then takes the *n*-th root of that product, where *n* is the number of values.  At the beginning of this notebook we imported the stats module from the scipy library.  It contains many functions that we will use in the statistical analysis of our data.  The `gmean` function calculates the geometric mean.  It can take a pandas series as argument."]},{"cell_type":"code","metadata":{"id":"aRDDpR2xwrt4"},"source":["stats.gmean(df.age)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7aD4OQQYhS_l"},"source":["### MEDIAN"]},{"cell_type":"markdown","metadata":{"id":"B4VdrM95TFq1"},"source":["The mean makes an assumption of the data values and that is that they should be normally distriuted.  We will learn much more about distributions later.  For now, we can view the normal distribution as the familiar bell-shaped curve."]},{"cell_type":"markdown","metadata":{"id":"uwAJDTiDTWPO"},"source":["Not all data value for a continuous numerical value follow a nice bell-shaped curve.  We can have quite different *shapes* (distributions) or many outliers (values that are way-off from all the others).  In these cases, the mean is not a good representative summary of all the data values.  Here, we rather use the median."]},{"cell_type":"markdown","metadata":{"id":"mhq-qnyDTo5X"},"source":["The **median** puts all the values in a sorted order.  If there are an odd number of values, then the median is the middle value, such that half of all the values are less than and the other half greater than the median.  If there are an even number of values, then the mean of the middle two values as taken."]},{"cell_type":"markdown","metadata":{"id":"YtCauitGhjmM"},"source":["- What is the median savings of customers older than $50$?"]},{"cell_type":"code","metadata":{"id":"fNCXvRhLhP2D"},"source":["# Using the .median() function\n","df[df.age > 50]['savings'].median()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZrdzCJ71vv5C"},"source":["This syntax can take some getting used to. We have learned about it in the previous notebook. Square bracket notation denotes indexing. The syntax then indicates the use of the `df` dataframe object. The indices that are included are decided by the `df.age > 50` code, called a conditional. Wherever this conditional returns a `True` value (age is greater than $50$) the index value of that row is included. The `savings` column is then used to return a series object. Finally, we call the `median` method on the series object."]},{"cell_type":"markdown","metadata":{"id":"_eUqs_2JozQo"},"source":["What about the median savings of those with a home loan and more than one vehicle?"]},{"cell_type":"markdown","metadata":{"id":"TtnBQYzywm4C"},"source":["We can use conditionals more than once by separating each by a pair of parentheses and an $\\&$ or $|$ symbol. This is called a compound statement. The question we ask of the data therefor also involves logic. More precisely, we have __and__ and __or__ questions. When using __and__, $\\&$, both sets of arguments must be true for the __compound statement__ to be true."]},{"cell_type":"code","metadata":{"id":"wDpg-9sjxSTw"},"source":["df[(df.home_loan == True) & (df.more_than_one_vehicle == True)].savings.median()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5xmOhB1TxjTP"},"source":["If we are interested in the median savings of those with either a home loan __or__ with more than one vehicle, only one of these have to be true to be included. Note that if both are true, it also leads to inclusion. The $|$ is used for _or_ statements."]},{"cell_type":"code","metadata":{"id":"HIBiZmSjxzNM"},"source":["df[(df.home_loan == True) | (df.more_than_one_vehicle == True)].savings.median()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iShT33mWxrvt"},"source":["#### Exercise"]},{"cell_type":"markdown","metadata":{"id":"7T8e8tzGx12Q"},"source":["Calculate the median age of the customers who have a home loan and no children."]},{"cell_type":"code","metadata":{"id":"m8R_UTK3xwYQ"},"source":["df.columns"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QqnAneXFxu1g"},"source":["#### Solution"]},{"cell_type":"code","metadata":{"id":"FK70KmVCyIIP"},"source":["df[(df.home_loan == True) & (df.children == 0)].age.median()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_uJCziGpyQpo"},"source":["There is an alternative solution to this probelm. The `loc` property takes as second argument, the column of interest. The first argument is reserved to select the rows."]},{"cell_type":"code","metadata":{"id":"_WeNyUp1yOKY"},"source":["df.loc[(df.home_loan == True) & (df.children == 0), 'age'].median()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0LxzmfOrh0OJ"},"source":["### MODE"]},{"cell_type":"markdown","metadata":{"id":"YPQs8H68T-tt"},"source":["The last measure of central tendency that we will take a look at is the mode.  The **mode** is used for categorical of discrete data types.  It returns the value(s) that occurs most commonly (and is hence not fit for continuous numerical variables).  If a single sample space element occurs most commonly, there is a single mode.  Sometimes more than one sample space element shares the spoils.  This variable is then __bimodal__.  As you might imagine, there are terms such as __tri-modal__ and __multi-modal__."]},{"cell_type":"markdown","metadata":{"id":"nbHeKQ_yh5CF"},"source":["- What is the mode of the `children` variable?"]},{"cell_type":"markdown","metadata":{"id":"1BGjsmonyvAZ"},"source":["We use the `value_counts` method do calculate the frequency.  The `ascending` argument is set to `False` by default and the `sort` is set to `True`, such that we get the mode at the top."]},{"cell_type":"code","metadata":{"id":"F2SOtFbvhrFt"},"source":["df.children.value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZSx4BfkLiTbK"},"source":["## MEASURES OF DISPERSION (SPREAD)"]},{"cell_type":"markdown","metadata":{"id":"xAdT_qaXVRad"},"source":["**Measure of dispersion** give us an indication of how spread out our numerical data values are."]},{"cell_type":"markdown","metadata":{"id":"d0Xj_HL-iYPe"},"source":["### STANDARD DEVIATION AND VARIANCE"]},{"cell_type":"markdown","metadata":{"id":"PfWzikN1Wl4N"},"source":["The **standard deviation** can be understood as the average difference between each continuous numerical data value and the mean of that variable.  Difference infers subtraction.  As some values will be larger than the mean and some smaller, subtraction from the mean will lead to positive numbers and negative numbers. In fact, from the way we calculate the mean, if we sum up all these differences (so as to calculate a mean difference), we will get 0.  To mitigate this, we square all of the differences.  Squaring (multiplying by itself) returns positive values.  Now we can sum all these values and divide by the number of values.  This gives us the **variance**."]},{"cell_type":"markdown","metadata":{"id":"8c_8KrJEXfb3"},"source":["Variances are very useful in statistics.  We need to express the spread in the same units as our variable for it to make sense as a summary statistic.  The *age* variable had a unit of years.  What then, is a $\\text{years}^2$.  Instead, we take the square root of the variance to get the standard deviation, now expressed in the same units as the variable and a true measure of the average difference between all the values and the mean."]},{"cell_type":"markdown","metadata":{"id":"e3GqwhglYCi3"},"source":["The `std` method returns the standard deviation of a series object and the `var` method returns the variance."]},{"cell_type":"markdown","metadata":{"id":"XTma-V9silDy"},"source":["- What is the standard deviation of the age of customerss who have a home loan versus those who do not?"]},{"cell_type":"code","metadata":{"id":"dn9I-qw9iOP0"},"source":["# Group by the Smoke column\n","df.groupby('home_loan')['age'].std()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DNER88cy0Jij"},"source":["### Exercise"]},{"cell_type":"markdown","metadata":{"id":"kO6wvmDf0Op8"},"source":["What is the variance in savings for those with a home loan or more than one vehicle?"]},{"cell_type":"markdown","metadata":{"id":"0ZElgSey0ZQS"},"source":["### Solution"]},{"cell_type":"code","metadata":{"id":"sVXWQqWE0br1"},"source":["df.loc[(df.home_loan == True) | (df.more_than_one_vehicle == True), 'savings'].var()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"plDKTmT9jRcy"},"source":["### RANGE"]},{"cell_type":"markdown","metadata":{"id":"idtxsoxhVeum"},"source":["The **range** is the difference between the minimum and the maximum value of a continuous numerical variable.  The `min` and the `max` methods for series objects give these values.  Let's see then how old our youngest and oldest customers are."]},{"cell_type":"markdown","metadata":{"id":"Pa41MN06jUAy"},"source":["- What is the minimum age of all the customers?"]},{"cell_type":"code","metadata":{"id":"O_7EvljzjIHJ"},"source":["# Using the .min() functuion\n","df.age.min()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WRrZ812Sjdto"},"source":["- What is the maximum age of all the customers?"]},{"cell_type":"code","metadata":{"id":"rP9QmY39jYGJ"},"source":["# Using the .max() function\n","df.age.max()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7CNM2qCnjnAq"},"source":["- What is the range in the age of all the customers?\n"]},{"cell_type":"markdown","metadata":{"id":"dpxIwNoy0FUB"},"source":["We simply subtract the minimum value from the maximum value."]},{"cell_type":"code","metadata":{"id":"h1UFkaz1jlP6"},"source":["# Difference between maximum and minimum ages\n","df.age.max() - df.age.min()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XSubh4N1j1Uh"},"source":["### QUANTILES"]},{"cell_type":"markdown","metadata":{"id":"GdwRlW3-Zjq0"},"source":["We divided our continuous numerical variables up into two halves for the median. We can divide them up into quarters as well.  In fact, we can divide it up at any percentage level from $0$% to $100$% (fraction of $0.0$ to $1.0$).  Here $0.0$ or $0$% would be the minimum value and $1.0$ or $100$% would be the maximum value.  Dividing the values up into these _bins_ give us **quantiles**."]},{"cell_type":"markdown","metadata":{"id":"5tIKnoESZ8Vu"},"source":["We can divide the values up into four bins with three values. These values are the **quartiles**."]},{"cell_type":"markdown","metadata":{"id":"J7MmotgG1jrw"},"source":["The lowest of these three values (the **first quartile**), divides the data into two parts, with a quarter being lower than that value and three-quarters being higher.  The second divides the data values equally (the median or **second quartile**).  The third is a value that has three-quarters of the values less than and a quarter more than it (the **third quartile**)."]},{"cell_type":"markdown","metadata":{"id":"fC36pjCHkCvx"},"source":["- What are the quartile values for the age of all the customers?"]},{"cell_type":"markdown","metadata":{"id":"BmjgyJwrape4"},"source":["The `quantile` method allows us to choose, as a fraction, any of these _cut-off_ values.  For the quartiles, we create a list `[0.25, 0.5, 0.75]`."]},{"cell_type":"code","metadata":{"id":"U9iW7ZNsjvht"},"source":["# Specifying the quartiles as fractions\n","df.age.quantile([0.25, 0.5, 0.75])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YPltHdznkZ83"},"source":["- What is the $95$<sup>th</sup> percentile values in age of the customers with a home loan versus those that do not have a home loan?"]},{"cell_type":"code","metadata":{"id":"xN5sCHO-kRJk"},"source":["df.groupby('home_loan')['age'].quantile(0.95)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PtyTBD7a1BFw"},"source":["The **interquartile range** is the difference between the third and the first quartile."]},{"cell_type":"markdown","metadata":{"id":"DXoM5qY-k4ll"},"source":["- What is the interquartile range of the age of all the customers?"]},{"cell_type":"code","metadata":{"id":"i1gNieQ4krVW"},"source":["df.age.quantile(0.75) - df.age.quantile(0.25)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A3_x8T-w1MAt"},"source":["## Conclusion"]},{"cell_type":"markdown","metadata":{"id":"T7MeslD41O96"},"source":["We now know a lot more about our data.  Be encouraged to learn even more by asking some questions about this mock business data set and see if you can calculate the required values."]},{"cell_type":"code","metadata":{"id":"eLPUPr11Qccg"},"source":[""],"execution_count":null,"outputs":[]}]}